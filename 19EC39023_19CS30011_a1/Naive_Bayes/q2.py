# -*- coding: utf-8 -*-
"""ML_Assign_1b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112XJVz5-p0m_pKU7NeNT4giL3ZsGLibP
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sys
from sklearn.model_selection import train_test_split
from math import sqrt, pi, exp
from random import randrange

"""## ASSIGNMENT 1 PART B"""

# Setting the output in a text file
fptr = open('outputFile.txt', 'w')

sys.stdout = fptr

# Reading data as input
data = pd.read_csv('Train_D_Bayesian.csv')
print("\t\t----Original Data----")
print(data)

#  Renaming the columns
data.columns = ['pelvic_incidence',
                'pelvic_tilt',
                'lumbar_lordosis_angle',
                'sacral_slope',
                'pelvic_radius',
                'degree_spondylolisthesis',
                'pelvic_slope',
                'Direct_tilt',
                'thoracic_slope',
                'cervical_tilt',
                'sacrum_angle',
                'scoliosis_slope',
                'Class_attr']
print("\t\t----Renaming the columns----")
print(data)

print("\t\t----Datatypes----")
print(data.dtypes)

# Encoding categorical variables
print("\t\t----Encoding categorical variables----")
data = data.replace({'Abnormal':1, 'Normal':0})
print(data)

# Dividing data into training data and testing data
training_data, testing_data = train_test_split(data, test_size=0.3)
print("----Splitting into training and testing data----")
print(training_data)
print(testing_data)

"""# Remove Outliers, Normalize"""

# Mean
def mean(numbers):
    return sum(numbers)/len(numbers)

# Standard Deviation
def stDev(numbers):
  avg = mean(numbers)
  var = 0
  for x in numbers:
    var += (x-avg)**2
  var /= len(numbers)
  return sqrt(var)

# Function to remove outliers from training data
def removeOutliers(data):
    for column in data:
        m = mean(data[column])
        dev = stDev(data[column])
        outlierVal = 2*m+5*dev
        data = data.loc[data[column]<=outlierVal]
    return data

print("\t\t----Removing outliers----")
print("Number of rows in the training data: %d" % len(training_data))
training_data = removeOutliers(training_data)
print("Number of rows after removing outliers: %d" % len(training_data))

# Normalise the training data and testing data
training_data_scaled = training_data
testing_data_scaled = testing_data
for column in training_data:
  training_data_scaled[column] = (training_data_scaled[column] - training_data_scaled[column].min()) / (training_data_scaled[column].max() - training_data_scaled[column].min())
for column in testing_data:
  testing_data_scaled[column] = (testing_data_scaled[column] - testing_data_scaled[column].min()) / (testing_data_scaled[column].max() - testing_data_scaled[column].min())
print("\t\t----Normalising training and testing data----")
print(training_data_scaled)
print(testing_data_scaled)

# Seperate rows based on label values and return as a dictionary
def separate_by_class(dataset):
    separated = dict()
    for i in range(len(dataset)):
        vector = dataset[i]
        class_value = vector[-1]
        if(class_value not in separated):
            separated[class_value] = list()
        separated[class_value].append(vector)
    return separated

def summarize_dataset(dataset):
    summaries = [(mean(column), stDev(column), len(column)) for column in zip(*dataset)]
    del(summaries[-1])
    return summaries

def summarize_by_class(dataset):
    separated = separate_by_class(dataset)
    summaries = dict()
    for class_value, rows in separated.items():
        summaries[class_value] = summarize_dataset(rows)
    return summaries

# Gaussian probability distribution
def calc_prob(x, m, dev, adder):
    exponent = exp(-((x-m)**2/(2 * dev**2)))
    val = (1/(sqrt(2*pi)*dev))*exponent
    if val < 0.0001:
        val += adder
    return val

def calc_class_prob(summaries, row, adder):
    total_rows = sum([summaries[label][0][2] for label in summaries])
    probs = dict()
    for class_value, class_summaries in summaries.items():
        probs[class_value] = summaries[class_value][0][2]/float(total_rows)
        for i in range(len(class_summaries)):
            m, dev, _ = class_summaries[i]
            probs[class_value] *= calc_prob(row[i], m, dev, adder)
    return probs

# Predict class for the given row
def predict(summaries, row, adder):
    probs = calc_class_prob(summaries, row, adder)
    ans, best_prob = None, -1
    for class_value, prob in probs.items():
        if ans is None or prob > best_prob:
            best_prob = prob
            ans = class_value
    return ans

# Naive Bayes Algorithm
def naive_bayes(train, test, adder):
    summarize = summarize_by_class(train)
    predictions = list()
    for row in test:
        output = predict(summarize, row, adder)
        predictions.append(output)
    return (predictions), summarize

# splitting dataset into k (5) folds
def cross_validation_splits(dataset):
    n_folds = 5
    dataset_split = list()
    dataset_copy = dataset.values.tolist()
    fold_size = int(len(dataset) / n_folds)
    for _ in range(n_folds):
        fold = list()
        while len(fold) < fold_size:
            index = randrange(len(dataset_copy))
            fold.append(dataset_copy[index])
            dataset_copy.pop(index)
        dataset_split.append(fold)
    return dataset_split

# Accuracy percentage
def calc_accuracy(actual, predicted):
    correct = 0
    for i in range(len(actual)):
        if actual[i] == predicted[i]:
            correct += 1
    return correct / float(len(actual)) * 100.0

def algo(training_data_scaled, adder):
    folds = cross_validation_splits(training_data_scaled)
    scores = list()
    best_summarize, best_accuracy = dict(), 0
    for fold in folds:
        print("\t\t----Fold----")
        print(fold)
        train_set = list(folds)
        train_set.remove(fold)
        train_set = sum(train_set, [])
        test_set = list()
        for row in fold:
            row_copy = list(row)
            test_set.append(row_copy)
            row_copy[-1] = None
        predicted, summarize = naive_bayes(train_set, test_set, adder)
        print("\t\t----Summarize----")
        print(summarize)
        actual = [row[-1] for row in fold]
        accuracy = calc_accuracy(actual, predicted)
        print("Accuracy: %.3f%%" % accuracy)
        if accuracy > best_accuracy:
            best_summarize, best_accuracy = summarize, accuracy
        scores.append(accuracy)
    return scores, best_summarize

def result(test_data_scaled, summary, adder):
    test_data = test_data_scaled.values.tolist()
    test_data_copy = list()
    for row in test_data:
        row_copy = list(row)
        test_data_copy.append(row_copy)
        row_copy[-1] = None
    predictions = list()
    for row in test_data_copy:
        output = predict(summary, row, adder)
        predictions.append(output)
    actual = [row[-1] for row in test_data]
    accuracy = calc_accuracy(actual, predictions)
    print('Accuracy on the testing data: %.3f%%' % accuracy)

print("\n\n\t\t----Applying 5 fold cross validation split with Naive Bayes Classifier----\n\n")
scores, summary = algo(training_data_scaled, 0)
print('Scores: %s' % scores)
print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))
print("\n\n\t\t----Applying on the testing data----\n\n")
result(testing_data_scaled, summary, 0)

# Applying Laplace correction 
print("\n\n\t\t----Applying 5 fold cross validation split with Naive Bayes Classifier using Laplace correction----\n\n")
scores, summary = algo(training_data_scaled, 0.0001)
print('Scores: %s' % scores)
print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))
print("\n\n\t\t----Applying on the testing data with Laplace correction----\n\n")
result(testing_data_scaled, summary, 0.0001)

fptr.close()

